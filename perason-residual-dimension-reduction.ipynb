{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of pearson residula on zebrafish data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the package and silence some warning information (mostly `is_categorical_dtype` warning from anndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import dynamo as dyn\n",
    "from dynamo.configuration import DKM\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is like R's sessionInfo() which helps you to debug version related bugs if any. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n",
    "\n",
    "Dynamo comes with a few builtin sample datasets so you can familiarize with dynamo before analyzing your own dataset.\n",
    "You can read your own data via `read`, `read_loom`, `read_h5ad`, `read_h5` (powered by the [anndata](https://anndata.readthedocs.io/en/latest/anndata.AnnData.html) package) or load_NASC_seq, etc. Here I just load the zebrafish sample data that comes with dynamo. This dataset has 4181 cells and 16940 genes. Its `.obs` attribute also included `condition`, `batch` information from the original study (you should also store those information to your `.obs` attribute which is essentially a Pandas Dataframe, see more at [anndata](https://anndata.readthedocs.io/en/latest/)). `Cluster`, `Cell_type`, umap coordinates that was originally analyzed with [Monocle 3](https://cole-trapnell-lab.github.io/monocle3/) are also provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|-----> Downloading data to ./data/zebrafish.h5ad\n"
     ]
    }
   ],
   "source": [
    "adata = dyn.sample_data.zebrafish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "from scipy import sparse\n",
    "import anndata\n",
    "\n",
    "\n",
    "def remove_rare_genes(counts, genes, minimum_detected_cells_per_gene):\n",
    "\n",
    "    if type(counts) in [sparse.csr.csr_matrix, sparse.csc.csc_matrix]:\n",
    "\n",
    "        # remove zero genes\n",
    "        nonzero_genes_idx = np.array(counts.sum(axis=0)).flatten() > 0\n",
    "\n",
    "        counts = counts[:, nonzero_genes_idx]\n",
    "        genes = genes[nonzero_genes_idx]\n",
    "\n",
    "        # count nonzero entries per gene\n",
    "        nonzero_coords = counts.nonzero()\n",
    "        n_nonzero = counts.count_nonzero()\n",
    "        is_nonzero = sparse.csc_matrix((np.ones(n_nonzero), nonzero_coords))\n",
    "        detected_cells_per_gene = np.array(is_nonzero.sum(axis=0)).flatten()\n",
    "\n",
    "        keep_genes = detected_cells_per_gene >= minimum_detected_cells_per_gene\n",
    "        counts_kept = counts[:, keep_genes]\n",
    "        genes_kept = genes[keep_genes]\n",
    "\n",
    "        print(\n",
    "            \"Of\",\n",
    "            len(detected_cells_per_gene),\n",
    "            \"total genes, returning\",\n",
    "            sum(keep_genes),\n",
    "            \"genes that are detected in %u or more cells.\"\n",
    "            % (minimum_detected_cells_per_gene),\n",
    "        )\n",
    "        print(\"Output shape:\", counts_kept.shape)\n",
    "\n",
    "        return counts_kept, np.array(genes_kept)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # remove zero genes\n",
    "        nonzero_genes_idx = np.sum(counts, axis=0) > 0\n",
    "        counts = counts[:, nonzero_genes_idx]\n",
    "        genes = genes[nonzero_genes_idx]\n",
    "\n",
    "        # remove genes that are detected in less then n cells\n",
    "        nonzero = counts > 0\n",
    "        cells_per_gene = np.sum(nonzero, axis=0)\n",
    "        include_genes = cells_per_gene >= minimum_detected_cells_per_gene\n",
    "        counts_kept = counts[:, include_genes]\n",
    "        genes_kept = genes[include_genes]\n",
    "        print(\n",
    "            \"Of\",\n",
    "            len(cells_per_gene),\n",
    "            \"total genes, returning\",\n",
    "            sum(include_genes),\n",
    "            \"genes that are detected in %u or more cells.\"\n",
    "            % (minimum_detected_cells_per_gene),\n",
    "        )\n",
    "        print(\"Output shape:\", counts_kept.shape)\n",
    "        return counts_kept, genes_kept\n",
    "\n",
    "\n",
    "def preprocess_adata_pearson_paper(adata):\n",
    "    counts, genes, cells = adata.X, np.array(adata.var_names), adata.obs_names\n",
    "\n",
    "    counts = counts.toarray()\n",
    "\n",
    "    # remove low depth cells\n",
    "    depths = np.array(np.sum(counts, axis=1)).flatten()\n",
    "    minimum_depth = 500\n",
    "    cells = cells[depths > minimum_depth]\n",
    "    counts = counts[depths > minimum_depth, :]\n",
    "    print(\n",
    "        \"Of\",\n",
    "        len(depths),\n",
    "        \"cells, returning\",\n",
    "        sum(depths > minimum_depth),\n",
    "        \"cells that have a depth larger than\",\n",
    "        minimum_depth,\n",
    "    )\n",
    "    print(\"New shape:\", counts.shape)\n",
    "\n",
    "    counts, genes = remove_rare_genes(counts, genes, minimum_detected_cells_per_gene=5)\n",
    "    counts = sparse.csr_matrix(counts)\n",
    "    res = anndata.AnnData(X=counts)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def compute_marginals(counts):\n",
    "    \"\"\"compute depths per cell (ns) and relative expression fractions per gene (ps)\"\"\"\n",
    "    ns = np.sum(counts, axis=1)\n",
    "    ps = np.sum(counts, axis=0)\n",
    "    ps = ps / np.sum(ps)\n",
    "    return np.squeeze(np.array(ns)), np.squeeze(np.array(ps))\n",
    "\n",
    "\n",
    "def monitor_progress(gene_id, n_genes, print_time_every=1000, print_dot_every=25):\n",
    "    if np.mod(gene_id, print_time_every) == 0:\n",
    "        print(\"\")\n",
    "        print(\n",
    "            \"##\",\n",
    "            datetime.now().time(),\n",
    "            \"##\",\n",
    "            gene_id,\n",
    "            \"of\",\n",
    "            n_genes,\n",
    "            \"genes fit\",\n",
    "            end=\"\",\n",
    "        )\n",
    "    if np.mod(gene_id, print_dot_every) == 0:\n",
    "        print(\".\", end=\"\")\n",
    "\n",
    "\n",
    "def fit_offsetmodel_w_statsmodel(counts, depths, name):\n",
    "    \"\"\"use statsmodel to fit offsetmodel (Eq. 3) and obtain beta0 (intercept) estimates, saving results to file\"\"\"\n",
    "    n_cells = counts.shape[0]\n",
    "    n_genes = counts.shape[1]\n",
    "\n",
    "    ##np.ones: will fit intercept beta0\n",
    "    X = np.ones((n_cells, 1))\n",
    "    ##log(depths): will be used as offsets\n",
    "    logdepths = np.log(depths)\n",
    "\n",
    "    beta0 = np.zeros(n_genes) * np.nan\n",
    "    for gene_id in range(n_genes):\n",
    "        offsetmodel = sm.Poisson(counts[:, gene_id], X, offset=logdepths)\n",
    "        result = offsetmodel.fit(disp=0)\n",
    "        beta0[gene_id] = result.params\n",
    "\n",
    "        monitor_progress(gene_id, n_genes)\n",
    "\n",
    "    res = dict(beta0=beta0)\n",
    "    # np.save('fit_results/fit_offsetmodel_w_statsmodel_%s' % (name),res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 4181 cells, returning 4157 cells that have a depth larger than 500\n",
      "New shape: (4157, 16940)\n",
      "Of 16589 total genes, returning 14555 genes that are detected in 5 or more cells.\n",
      "Output shape: (4157, 14555)\n"
     ]
    }
   ],
   "source": [
    "adata = preprocess_adata_pearson_paper(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "\n",
    "def pearson_residuals(counts, theta, clipping=True):\n",
    "    \"\"\"Computes analytical residuals for NB model with a fixed theta, clipping outlier residuals to sqrt(N)\"\"\"\n",
    "    counts_sum0 = np.sum(counts, axis=0, keepdims=True)\n",
    "    counts_sum1 = np.sum(counts, axis=1, keepdims=True)\n",
    "    counts_sum = np.sum(counts)\n",
    "\n",
    "    # get residuals\n",
    "    mu = counts_sum1 @ counts_sum0 / counts_sum\n",
    "    z = (counts - mu) / np.sqrt(mu + mu ** 2 / theta)\n",
    "\n",
    "    # clip to sqrt(n)\n",
    "    if clipping:\n",
    "        n = counts.shape[0]\n",
    "        z[z > np.sqrt(n)] = np.sqrt(n)\n",
    "        z[z < -np.sqrt(n)] = -np.sqrt(n)\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "def pearson_residuals_PCA(adata, theta=100, n_comps=50):\n",
    "    adata = adata.copy()\n",
    "    counts = adata.X.toarray()\n",
    "    return sc.pp.pca(pearson_residuals(counts, theta), random_state=42, n_comps=n_comps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_reduced_counts = pearson_residuals_PCA(adata)\n",
    "adata.obsm[\"X_pca_pearson\"] = pca_reduced_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-15.597142  ,  -6.3667483 ,  -2.144211  , ...,   0.6135125 ,\n",
       "         -0.42440122,  -0.07755979],\n",
       "       [-13.199008  ,  -9.480839  ,  -6.4491725 , ...,   1.1760699 ,\n",
       "          0.28251767,  -0.39280787],\n",
       "       [-25.472523  ,   1.0001048 ,  27.995993  , ...,  -0.5333733 ,\n",
       "          2.693091  ,   0.36366162],\n",
       "       ...,\n",
       "       [ 10.02985   , -14.028355  , -12.073074  , ...,  -1.8847305 ,\n",
       "         -2.2358758 ,  -3.1401749 ],\n",
       "       [  8.808733  , -15.998152  , -11.24421   , ...,   1.3771492 ,\n",
       "         -4.614617  ,   3.7940211 ],\n",
       "       [ -5.928084  , -24.506561  , -24.752354  , ...,   2.0322068 ,\n",
       "          6.9996734 ,  -1.9071083 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obsm[\"X_pca_pearson\"]\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0f224693fc3f3b337b469fdaf7389d3b291b17a90dca45f35bda4453932d9dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('dynamo-dev': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
